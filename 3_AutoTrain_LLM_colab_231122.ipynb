{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QXqPVg2P7Im9A7vJsBQpzBqsRsYbzXPD?usp=sharing)"
      ],
      "metadata": {
        "id": "-g5npBe68eSB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvh6pvko5Oas"
      },
      "source": [
        "# Autotrain LLAMA2 fine-tuning\n",
        "\n",
        "231122\n",
        "\n",
        "- [ref](https://youtu.be/GjZ1a0OJqGk?feature=shared)\n",
        "\n",
        "- [autotrain](https://github.com/huggingface/autotrain-advanced)을 사용하는 경우 [link](https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/trainers/clm/__main__.py) 코드 변형해서 쓰면 된다\n",
        "\n",
        "Params: Namespace(version=False, train=True, deploy=False, inference=False, data_path='royboy0416/ko-alpaca', train_split='train', valid_split=None, text_column='text', model='abhishek/llama-2-7b-hf-small-shards', learning_rate=0.0002, num_train_epochs=2, train_batch_size=2, warmup_ratio=0.1, gradient_accumulation_steps=4, optimizer='adamw_torch', scheduler='linear', weight_decay=0.01, max_grad_norm=1.0, seed=42, add_eos_token=False, block_size=1024, use_peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, project_name='my_autotrain_llm', evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, fp16=True, push_to_hub=True, use_int8=False, model_max_length=1024, repo_id='keapsteady/autotrain_test', use_int4=True, trainer='default', target_modules=None, merge_adapter=False, token='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', backend='default', username=None, use_flash_attention_2=False, func=<function run_llm_command_factory at 0x7fc860cef760>)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 에러없는 과거버전 autotrain으로 설치\n",
        "!git clone https://github.com/airobotlab/KoChatGPT.git\n",
        "%cd ./KoChatGPT\n",
        "!unzip autotrain-advanced_231012 -d ./autotrain-advanced_231012\n",
        "%cd ./autotrain-advanced_231012\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qBN-x20G30aY",
        "outputId": "4ebeaf9d-cd34-48b3-c092-82906e9f8b90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoChatGPT'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 269 (delta 67), reused 53 (delta 53), pack-reused 169\u001b[K\n",
            "Receiving objects: 100% (269/269), 48.80 MiB | 26.67 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n",
            "/content/KoChatGPT\n",
            "Archive:  autotrain-advanced_231012.zip\n",
            "  inflating: ./autotrain-advanced_231012/examples/README.md  \n",
            "  inflating: ./autotrain-advanced_231012/examples/text_classification_binary.py  \n",
            "  inflating: ./autotrain-advanced_231012/examples/text_classification_multiclass.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/backend.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/config.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/dataset.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/logging.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/tasks.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/apps/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/common.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/dreambooth.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/apps/image_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/llm.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/main.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/tabular.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/text_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/autotrain.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_api.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_app.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_dreambooth.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_image_classification.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_llm.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_setup.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_spacerunner.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_tabular.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_text_classification.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/autotrain.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_api.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_app.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_dreambooth.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_image_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_llm.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_setup.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_spacerunner.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_tabular.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_text_classification.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/infer/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/infer/text_generation.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/dreambooth.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/tabular.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/text.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/vision.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/preprocessor/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/dreambooth.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/tabular.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/text.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/vision.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/tests/test_dummy.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/__pycache__/common.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/__main__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/callbacks.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/params.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/callbacks.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/__main__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/datasets.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/params.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/trainer.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/datasets.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/trainer.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__pycache__/params.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__pycache__/params.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/dataset.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__pycache__/params.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__pycache__/params.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/dataset.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/utils.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/common.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/lm_trainer.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__init__.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/allowed_file_types.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/api.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/app.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/backend.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/config.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/dataset.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/dreambooth_app.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/help.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/languages.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/logging.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/project.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/splits.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/tasks.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/PKG-INFO  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/SOURCES.txt  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/dependency_links.txt  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/entry_points.txt  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/requires.txt  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/top_level.txt  \n",
            "  inflating: ./autotrain-advanced_231012/.dockerignore  \n",
            "  inflating: ./autotrain-advanced_231012/.gitignore  \n",
            "  inflating: ./autotrain-advanced_231012/Dockerfile  \n",
            "  inflating: ./autotrain-advanced_231012/LICENSE  \n",
            "  inflating: ./autotrain-advanced_231012/Makefile  \n",
            "  inflating: ./autotrain-advanced_231012/README.md  \n",
            "  inflating: ./autotrain-advanced_231012/requirements.txt  \n",
            "  inflating: ./autotrain-advanced_231012/setup.cfg  \n",
            "  inflating: ./autotrain-advanced_231012/setup.py  \n",
            "/content/KoChatGPT/autotrain-advanced_231012\n",
            "Obtaining file:///content/KoChatGPT/autotrain-advanced_231012\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (1.3.1)\n",
            "Collecting codecarbon==2.2.3 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.14.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==3.0.2 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Collecting joblib==1.3.1 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (1.5.3)\n",
            "Collecting optuna==3.3.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.0.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.4 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.11 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.3.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==2.3.6 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.6 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (0.19.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (2.31.0)\n",
            "Collecting gradio==3.41.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark==0.2.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (2.14.1)\n",
            "Collecting peft (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading trl-0.7.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (4.35.2)\n",
            "Collecting accelerate (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading diffusers-0.23.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (1.11.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (4.8.1.78)\n",
            "Collecting arrow (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0) (8.1.7)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (1.4.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (2.1.0+cu118)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer==3.0.2->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0) (2.0.23)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (2023.7.22)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced==0.6.36.dev0) (2023.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced==0.6.36.dev0) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->autotrain-advanced==0.6.36.dev0) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.16.4->autotrain-advanced==0.6.36.dev0) (3.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced==0.6.36.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced==0.6.36.dev0) (2023.3.post1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->autotrain-advanced==0.6.36.dev0) (6.8.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers->autotrain-advanced==0.6.36.dev0) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (0.7.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->autotrain-advanced==0.6.36.dev0) (0.15.0)\n",
            "Collecting tyro>=0.5.11 (from trl->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading tyro-0.5.17-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.5/100.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.5.0->optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced==0.6.36.dev0) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (2023.9.26)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.3.0->autotrain-advanced==0.6.36.dev0) (3.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading shtab-1.6.4-py3-none-any.whl (13 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow->codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting httpcore (from httpx->gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->autotrain-advanced==0.6.36.dev0) (3.17.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.12.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced==0.6.36.dev0) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (0.1.2)\n",
            "Building wheels for collected packages: ipadic, sacremoses, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=b9cd6c96c78a3fb00a90f4de02a58209600d9771d22b57482f7ec885d32d011e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=cebb483771793f3d8559bdf3c5b94751bdb128c1fe7f19096057645508bacdf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=35663e2e231c2a2561e95e340a3e729cceef4fbb4266fa13dfae02b5e6624b6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ipadic sacremoses ffmpy\n",
            "Installing collected packages: types-python-dateutil, sentencepiece, pydub, ipadic, fuzzywuzzy, ffmpy, bitsandbytes, werkzeug, websockets, typing-extensions, tqdm, shtab, semantic-version, rapidfuzz, python-multipart, pynvml, pyarrow-hotfix, protobuf, Pillow, packaging, orjson, Mako, loguru, joblib, h11, einops, docstring-parser, dill, colorlog, cmaes, aiofiles, xgboost, uvicorn, tiktoken, starlette, scikit-learn, sacremoses, responses, pydantic, multiprocess, jiwer, httpcore, arrow, tyro, invisible-watermark, httpx, fastapi, diffusers, codecarbon, alembic, accelerate, optuna, gradio-client, datasets, trl, peft, gradio, evaluate, autotrain-advanced\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.1\n",
            "    Uninstalling Werkzeug-3.0.1:\n",
            "      Successfully uninstalled Werkzeug-3.0.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.2\n",
            "    Uninstalling xgboost-2.0.2:\n",
            "      Successfully uninstalled xgboost-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Running setup.py develop for autotrain-advanced\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.0 Pillow-10.0.0 accelerate-0.24.1 aiofiles-23.2.1 alembic-1.12.1 arrow-1.3.0 autotrain-advanced-0.6.36.dev0 bitsandbytes-0.41.2.post2 cmaes-0.10.0 codecarbon-2.2.3 colorlog-6.7.0 datasets-2.14.7 diffusers-0.23.1 dill-0.3.7 docstring-parser-0.15 einops-0.6.1 evaluate-0.3.0 fastapi-0.104.1 ffmpy-0.3.1 fuzzywuzzy-0.18.0 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-3.0.2 joblib-1.3.1 loguru-0.7.0 multiprocess-0.70.15 optuna-3.3.0 orjson-3.9.10 packaging-23.1 peft-0.6.2 protobuf-4.23.4 pyarrow-hotfix-0.5 pydantic-1.10.11 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.6 rapidfuzz-2.13.7 responses-0.18.0 sacremoses-0.0.53 scikit-learn-1.3.0 semantic-version-2.10.0 sentencepiece-0.1.99 shtab-1.6.4 starlette-0.27.0 tiktoken-0.5.1 tqdm-4.65.0 trl-0.7.4 types-python-dateutil-2.8.19.14 typing-extensions-4.8.0 tyro-0.5.17 uvicorn-0.24.0.post1 websockets-11.0.3 werkzeug-2.3.6 xgboost-1.7.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EEQPUrmu3LUh"
      },
      "outputs": [],
      "source": [
        "# # 작은모델로 autotrain 체크하는 코드\n",
        "# autotrain llm --train --model \"abhishek/llama-2-7b-hf-small-shards\" --project_name \"my_autotrain_llm\" --data_path \"aboonaji/alpaca_micro_demo\" --text_column \"text\" --learning_rate 0.0002 --train_batch_size 2 --num_train_epochs 2 --block_size 1024 --warmup_ratio 0.1 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --weight_decay 0.01 --gradient_accumulation_steps 4  --fp16 --use_peft --use_int4 --push-to-hub --token \"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\" --repo-id \"keepsteady/autotrain_test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOGbcWeQ3LUh",
        "outputId": "46367621-e5f4-4196-b42e-fc5b33710ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "### Instruction: Identify the odd one out.\n",
            "### Input: Twitter, Instagram, Telegram\n",
            "### Response: Telegram\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "지시 = 'Identify the odd one out.'\n",
        "입력 = 'Twitter, Instagram, Telegram'\n",
        "출력 = 'Telegram'\n",
        "\n",
        "text = f'{description}\\n### Instruction: {지시}\\n### Input: {입력}\\n### Response: {출력}'\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEBsenlr3LUi",
        "outputId": "52401bcb-f9dd-4134-8d3b-355b2705ac8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction: Identify the odd one out.\\n### Input: Twitter, Instagram, Telegram\\n### Response: Telegram'},\n",
              " {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction: Identify the odd one out.\\n### Input: Twitter, Instagram, Telegram\\n### Response: Telegram'},\n",
              " {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction: Identify the odd one out.\\n### Input: Twitter, Instagram, Telegram\\n### Response: Telegram'}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "custom_data = [\n",
        "    {\"text\": text},\n",
        "    {\"text\": text},\n",
        "    {\"text\": text}\n",
        "]\n",
        "\n",
        "custom_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE06uCs33LUi",
        "outputId": "99c9e5b7-eefb-4a97-853d-d061a53438fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "### Instruction: Identify the odd one out.\n",
            "### Input: Twitter, Instagram, Telegram\n",
            "### Response: Telegram\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "\n",
        "\n",
        "지시 = 'Identify the odd one out.'\n",
        "입력 = 'Twitter, Instagram, Telegram'\n",
        "출력 = 'Telegram'\n",
        "\n",
        "text = f'{description}\\n### Instruction: {지시}\\n### Input: {입력}\\n### Response: {출력}'\n",
        "print(text)\n",
        "\n",
        "\n",
        "\n",
        "custom_data = [\n",
        "    {\"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to\"},\n",
        "    {\"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to\"},\n",
        "    {\"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to\"}\n",
        "]\n",
        "\n",
        "# 위에서 설정한 학습 데이터를 파일로 저장합니다.\n",
        "import json\n",
        "with open(\"custom_data.jsonl\", \"w\", encoding='utf-8') as json_file:\n",
        "    json.dump(custom_data, json_file, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSeDGNNJ3LUi",
        "outputId": "30a753ef-e8f0-43b9-f5e9-f708a8bd054e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autotrain llm --train --project_name test                     --model TinyPixel/Llama-2-7B-bf16-sharded                     --data_path timdettmers/openassistant-guanaco                     --text_column \"text\" \\                    \n",
            "                    --use_peft                     --use_int4                     --learning_rate 2e-4                     --train_batch_size 2                     --num_train_epochs 2                     --trainer sft                     --model_max_length 2048                     --push_to_hub                     --repo_id keepsteady/test                     --block_size 2048\n"
          ]
        }
      ],
      "source": [
        "# single line command!\n",
        "# \"quantumaikr/KoreanLM-llama-2-7B-finetuned\"  # 한국어\n",
        "# \"TinyPixel/Llama-2-7B-bf16-sharded\"  # 영어\n",
        "\n",
        "project_name='test'\n",
        "model = 'TinyPixel/Llama-2-7B-bf16-sharded'\n",
        "data_path = 'timdettmers/openassistant-guanaco'\n",
        "# data_path = 'tatsu-lab/alpaca'\n",
        "\n",
        "train_batch_size = 2\n",
        "num_train_epochs = 2\n",
        "model_max_length = 2048\n",
        "repo_id = 'keepsteady/test'\n",
        "\n",
        "cmd = f'''autotrain llm --train --project_name {project_name} \\\n",
        "                    --model {model} \\\n",
        "                    --data_path {data_path} \\\n",
        "                    --text_column \\\"text\\\" \\\n",
        "                    --use_peft \\\n",
        "                    --use_int4 \\\n",
        "                    --learning_rate 2e-4 \\\n",
        "                    --train_batch_size {train_batch_size} \\\n",
        "                    --num_train_epochs {num_train_epochs} \\\n",
        "                    --trainer sft \\\n",
        "                    --model_max_length {model_max_length} \\\n",
        "                    --push_to_hub \\\n",
        "                    --repo_id {repo_id} \\\n",
        "                    --block_size 2048'''\n",
        "\n",
        "print(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7dPE3tY3LUj",
        "outputId": "a8fc1a82-dc06-42d9-88ab-a3cad122cb60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, train=True, deploy=False, inference=False, data_path='timdettmers/openassistant-guanaco', train_split='train', valid_split=None, text_column='text', model='TinyPixel/Llama-2-7B-bf16-sharded', learning_rate=0.0002, num_train_epochs=2, train_batch_size=2, warmup_ratio=0.1, gradient_accumulation_steps=1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, seed=42, add_eos_token=False, block_size=2048, use_peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, project_name='test', evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, fp16=False, push_to_hub=True, use_int8=False, model_max_length=2048, repo_id='keepsteady/test', use_int4=True, trainer='sft', target_modules=None, merge_adapter=False, token=None, backend='default', username=None, use_flash_attention_2=False, func=<function run_llm_command_factory at 0x781d97ec5090>)\u001b[0m\n",
            "Downloading readme: 100% 395/395 [00:00<00:00, 1.65MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
            "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
            "Downloading data files:   0% 0/2 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/20.9M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  20% 4.19M/20.9M [00:00<00:01, 13.4MB/s]\u001b[A\n",
            "Downloading data:  60% 12.6M/20.9M [00:00<00:00, 32.2MB/s]\u001b[A\n",
            "Downloading data: 100% 20.9M/20.9M [00:00<00:00, 36.9MB/s]\n",
            "Downloading data files:  50% 1/2 [00:00<00:00,  1.76it/s]\n",
            "Downloading data:   0% 0.00/1.11M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100% 1.11M/1.11M [00:00<00:00, 5.06MB/s]\n",
            "Downloading data files: 100% 2/2 [00:00<00:00,  2.53it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 2209.85it/s]\n",
            "Generating train split: 9846 examples [00:00, 142187.63 examples/s]\n",
            "Generating test split: 518 examples [00:00, 114506.67 examples/s]\n",
            "tokenizer_config.json: 100% 676/676 [00:00<00:00, 3.13MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 441MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 7.19MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 2.30MB/s]\n",
            "config.json: 100% 626/626 [00:00<00:00, 4.11MB/s]\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 96.1MB/s]\n",
            "Downloading shards:   0% 0/14 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00014.bin:   0% 0.00/981M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:   4% 41.9M/981M [00:00<00:02, 394MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  10% 94.4M/981M [00:00<00:02, 414MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  15% 147M/981M [00:00<00:02, 414MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  19% 189M/981M [00:00<00:01, 416MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  25% 241M/981M [00:00<00:01, 429MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  30% 294M/981M [00:00<00:01, 433MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  35% 346M/981M [00:00<00:01, 441MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  41% 398M/981M [00:00<00:01, 421MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  46% 451M/981M [00:01<00:01, 429MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  51% 503M/981M [00:01<00:01, 425MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  57% 556M/981M [00:01<00:01, 426MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  62% 608M/981M [00:01<00:00, 431MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  67% 661M/981M [00:01<00:00, 412MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  72% 703M/981M [00:01<00:00, 403MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  76% 744M/981M [00:01<00:00, 395MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  80% 786M/981M [00:01<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  84% 828M/981M [00:02<00:00, 371MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  89% 870M/981M [00:02<00:00, 349MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin:  93% 912M/981M [00:02<00:00, 352MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00014.bin: 100% 981M/981M [00:02<00:00, 390MB/s]\n",
            "Downloading shards:   7% 1/14 [00:02<00:34,  2.62s/it]\n",
            "pytorch_model-00002-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:   1% 10.5M/967M [00:00<00:09, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:   4% 41.9M/967M [00:00<00:04, 199MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00014.bin:   9% 83.9M/967M [00:00<00:03, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  12% 115M/967M [00:00<00:02, 292MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  15% 147M/967M [00:00<00:02, 299MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  20% 189M/967M [00:00<00:02, 326MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  24% 231M/967M [00:00<00:02, 351MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  28% 273M/967M [00:00<00:01, 366MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  33% 315M/967M [00:00<00:01, 380MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  37% 357M/967M [00:01<00:01, 389MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  41% 398M/967M [00:01<00:01, 396MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  46% 440M/967M [00:01<00:01, 395MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  50% 482M/967M [00:01<00:01, 399MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  54% 524M/967M [00:01<00:01, 379MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  59% 566M/967M [00:01<00:01, 380MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  63% 608M/967M [00:01<00:00, 384MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  67% 650M/967M [00:01<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  72% 692M/967M [00:01<00:00, 339MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  76% 734M/967M [00:02<00:00, 333MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  80% 776M/967M [00:02<00:00, 336MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  85% 818M/967M [00:02<00:00, 329MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  89% 860M/967M [00:02<00:00, 330MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin:  93% 902M/967M [00:02<00:00, 320MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00014.bin: 100% 967M/967M [00:02<00:00, 336MB/s]\n",
            "Downloading shards:  14% 2/14 [00:05<00:34,  2.83s/it]\n",
            "pytorch_model-00003-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:   1% 10.5M/967M [00:00<00:21, 44.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:   3% 31.5M/967M [00:00<00:10, 91.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:   7% 62.9M/967M [00:00<00:05, 158MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  11% 105M/967M [00:00<00:03, 220MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  15% 147M/967M [00:00<00:03, 258MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  20% 189M/967M [00:00<00:02, 283MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  24% 231M/967M [00:00<00:02, 303MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  28% 273M/967M [00:01<00:02, 323MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  33% 315M/967M [00:01<00:01, 338MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  37% 357M/967M [00:01<00:01, 347MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  41% 398M/967M [00:01<00:01, 355MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  46% 440M/967M [00:01<00:01, 346MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  50% 482M/967M [00:01<00:01, 346MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  54% 524M/967M [00:01<00:01, 348MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  59% 566M/967M [00:01<00:01, 336MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  63% 608M/967M [00:02<00:01, 342MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  67% 650M/967M [00:02<00:00, 344MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  72% 692M/967M [00:02<00:00, 351MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  76% 734M/967M [00:02<00:00, 354MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  80% 776M/967M [00:02<00:00, 356MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  85% 818M/967M [00:02<00:00, 363MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  89% 860M/967M [00:02<00:00, 372MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin:  93% 902M/967M [00:02<00:00, 326MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00014.bin: 100% 967M/967M [00:03<00:00, 308MB/s]\n",
            "Downloading shards:  21% 3/14 [00:08<00:33,  3.05s/it]\n",
            "pytorch_model-00004-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:   2% 21.0M/990M [00:00<00:06, 143MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:   6% 62.9M/990M [00:00<00:03, 238MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  11% 105M/990M [00:00<00:02, 295MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  15% 147M/990M [00:00<00:02, 326MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  19% 189M/990M [00:00<00:02, 271MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  23% 231M/990M [00:00<00:02, 278MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  26% 262M/990M [00:00<00:02, 269MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  30% 294M/990M [00:01<00:02, 280MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  34% 336M/990M [00:01<00:02, 302MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  37% 367M/990M [00:01<00:02, 298MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  41% 409M/990M [00:01<00:01, 310MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  46% 451M/990M [00:01<00:01, 316MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  50% 493M/990M [00:01<00:01, 322MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  54% 535M/990M [00:01<00:01, 323MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  58% 577M/990M [00:01<00:01, 338MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  62% 619M/990M [00:02<00:01, 343MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  67% 661M/990M [00:02<00:00, 333MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  71% 703M/990M [00:02<00:00, 327MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  75% 744M/990M [00:02<00:00, 332MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  79% 786M/990M [00:02<00:00, 327MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  84% 828M/990M [00:02<00:00, 326MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  88% 870M/990M [00:02<00:00, 321MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  92% 912M/990M [00:02<00:00, 314MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin:  95% 944M/990M [00:03<00:00, 310MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00014.bin: 100% 990M/990M [00:03<00:00, 307MB/s]\n",
            "Downloading shards:  29% 4/14 [00:12<00:31,  3.16s/it]\n",
            "pytorch_model-00005-of-00014.bin:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:   1% 10.5M/944M [00:00<00:16, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:   3% 31.5M/944M [00:00<00:09, 99.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:   7% 62.9M/944M [00:00<00:05, 158MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  11% 105M/944M [00:00<00:03, 220MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  16% 147M/944M [00:00<00:03, 263MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  20% 189M/944M [00:00<00:02, 292MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  24% 231M/944M [00:00<00:02, 324MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  29% 273M/944M [00:01<00:01, 337MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  33% 315M/944M [00:01<00:01, 346MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  38% 357M/944M [00:01<00:01, 361MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  42% 398M/944M [00:01<00:01, 374MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  47% 440M/944M [00:01<00:01, 337MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  51% 482M/944M [00:01<00:01, 354MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  57% 535M/944M [00:01<00:01, 374MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  61% 577M/944M [00:01<00:00, 369MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  66% 619M/944M [00:01<00:00, 377MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  70% 661M/944M [00:02<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  74% 703M/944M [00:02<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  79% 744M/944M [00:02<00:00, 388MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  83% 786M/944M [00:02<00:00, 383MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  88% 828M/944M [00:02<00:00, 389MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin:  92% 870M/944M [00:02<00:00, 398MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00014.bin: 100% 944M/944M [00:02<00:00, 333MB/s]\n",
            "Downloading shards:  36% 5/14 [00:15<00:27,  3.08s/it]\n",
            "pytorch_model-00006-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:   2% 21.0M/990M [00:00<00:05, 189MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:   6% 62.9M/990M [00:00<00:03, 285MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  11% 105M/990M [00:00<00:02, 307MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  15% 147M/990M [00:00<00:02, 321MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  19% 189M/990M [00:00<00:02, 320MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  23% 231M/990M [00:00<00:02, 329MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  28% 273M/990M [00:00<00:02, 330MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  32% 315M/990M [00:00<00:02, 336MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  36% 357M/990M [00:01<00:01, 351MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  40% 398M/990M [00:01<00:01, 360MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  44% 440M/990M [00:01<00:01, 370MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  49% 482M/990M [00:01<00:01, 375MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  53% 524M/990M [00:01<00:01, 381MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  57% 566M/990M [00:01<00:01, 388MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  61% 608M/990M [00:01<00:00, 391MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  66% 650M/990M [00:01<00:00, 395MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  70% 692M/990M [00:01<00:00, 401MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  74% 734M/990M [00:02<00:00, 399MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  78% 776M/990M [00:02<00:00, 401MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  83% 818M/990M [00:02<00:00, 388MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  87% 860M/990M [00:02<00:00, 377MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  91% 902M/990M [00:02<00:00, 369MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin:  95% 944M/990M [00:02<00:00, 347MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00014.bin: 100% 990M/990M [00:02<00:00, 360MB/s]\n",
            "Downloading shards:  43% 6/14 [00:18<00:24,  3.09s/it]\n",
            "pytorch_model-00007-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:   4% 41.9M/967M [00:00<00:02, 409MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  10% 94.4M/967M [00:00<00:02, 415MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  15% 147M/967M [00:00<00:01, 416MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  20% 189M/967M [00:00<00:01, 408MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  24% 231M/967M [00:00<00:01, 376MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  28% 273M/967M [00:00<00:01, 358MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  33% 315M/967M [00:00<00:01, 346MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  37% 357M/967M [00:01<00:02, 231MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  41% 398M/967M [00:01<00:02, 262MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  46% 440M/967M [00:01<00:01, 288MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  50% 482M/967M [00:01<00:01, 307MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  54% 524M/967M [00:01<00:01, 317MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  59% 566M/967M [00:01<00:01, 326MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  63% 608M/967M [00:01<00:01, 334MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  67% 650M/967M [00:01<00:00, 328MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  72% 692M/967M [00:02<00:00, 327MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  76% 734M/967M [00:02<00:00, 338MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  80% 776M/967M [00:02<00:00, 284MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  84% 807M/967M [00:02<00:00, 289MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  87% 839M/967M [00:02<00:00, 293MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  91% 881M/967M [00:02<00:00, 302MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin:  95% 923M/967M [00:02<00:00, 309MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00014.bin: 100% 967M/967M [00:03<00:00, 315MB/s]\n",
            "Downloading shards:  50% 7/14 [00:21<00:21,  3.12s/it]\n",
            "pytorch_model-00008-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:   2% 21.0M/967M [00:00<00:06, 140MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:   5% 52.4M/967M [00:00<00:04, 220MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  10% 94.4M/967M [00:00<00:03, 268MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  14% 136M/967M [00:00<00:02, 291MB/s] \u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  17% 168M/967M [00:00<00:02, 293MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  21% 199M/967M [00:00<00:02, 292MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  24% 231M/967M [00:00<00:02, 297MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  27% 262M/967M [00:00<00:02, 300MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  30% 294M/967M [00:01<00:02, 295MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  34% 325M/967M [00:01<00:02, 281MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  38% 367M/967M [00:01<00:02, 300MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  42% 409M/967M [00:01<00:01, 317MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  47% 451M/967M [00:01<00:01, 331MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  51% 493M/967M [00:01<00:01, 345MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  55% 535M/967M [00:01<00:01, 358MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  60% 577M/967M [00:01<00:01, 370MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  64% 619M/967M [00:01<00:00, 381MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  68% 661M/967M [00:02<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  73% 703M/967M [00:02<00:00, 389MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  77% 744M/967M [00:02<00:00, 389MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  81% 786M/967M [00:02<00:00, 381MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  86% 828M/967M [00:02<00:00, 378MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  90% 870M/967M [00:02<00:00, 377MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin:  94% 912M/967M [00:02<00:00, 375MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00014.bin: 100% 967M/967M [00:02<00:00, 334MB/s]\n",
            "Downloading shards:  57% 8/14 [00:24<00:18,  3.09s/it]\n",
            "pytorch_model-00009-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:   4% 41.9M/990M [00:00<00:02, 351MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  10% 94.4M/990M [00:00<00:02, 385MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  14% 136M/990M [00:00<00:02, 368MB/s] \u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  18% 178M/990M [00:00<00:02, 361MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  22% 220M/990M [00:00<00:02, 369MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  26% 262M/990M [00:00<00:02, 353MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  31% 304M/990M [00:00<00:01, 344MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  35% 346M/990M [00:00<00:01, 326MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  39% 388M/990M [00:01<00:01, 325MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  43% 430M/990M [00:01<00:01, 336MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  48% 472M/990M [00:01<00:01, 343MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  52% 514M/990M [00:01<00:01, 337MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  56% 556M/990M [00:01<00:01, 338MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  60% 598M/990M [00:01<00:01, 339MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  65% 640M/990M [00:01<00:01, 334MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  69% 682M/990M [00:02<00:00, 327MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  73% 724M/990M [00:02<00:00, 329MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  77% 765M/990M [00:02<00:00, 338MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  82% 807M/990M [00:02<00:00, 340MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  86% 849M/990M [00:02<00:00, 346MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  90% 891M/990M [00:02<00:00, 344MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin:  94% 933M/990M [00:02<00:00, 335MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00014.bin: 100% 990M/990M [00:02<00:00, 338MB/s]\n",
            "Downloading shards:  64% 9/14 [00:27<00:15,  3.07s/it]\n",
            "pytorch_model-00010-of-00014.bin:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:   2% 21.0M/944M [00:00<00:05, 183MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:   4% 41.9M/944M [00:00<00:04, 198MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:   7% 62.9M/944M [00:00<00:05, 172MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  10% 94.4M/944M [00:00<00:03, 214MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  14% 136M/944M [00:00<00:03, 266MB/s] \u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  19% 178M/944M [00:00<00:02, 305MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  23% 220M/944M [00:00<00:02, 332MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  29% 273M/944M [00:00<00:01, 364MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  34% 325M/944M [00:01<00:01, 385MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  40% 377M/944M [00:01<00:01, 402MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  46% 430M/944M [00:01<00:01, 411MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  51% 482M/944M [00:01<00:01, 421MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  57% 535M/944M [00:01<00:00, 426MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  62% 587M/944M [00:01<00:00, 429MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  68% 640M/944M [00:01<00:00, 432MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  73% 692M/944M [00:01<00:00, 432MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  79% 744M/944M [00:02<00:00, 429MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  84% 797M/944M [00:02<00:00, 409MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  89% 839M/944M [00:02<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin:  93% 881M/944M [00:02<00:00, 375MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00014.bin: 100% 944M/944M [00:02<00:00, 367MB/s]\n",
            "Downloading shards:  71% 10/14 [00:30<00:11,  2.95s/it]\n",
            "pytorch_model-00011-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:   2% 21.0M/990M [00:00<00:05, 191MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:   5% 52.4M/990M [00:00<00:04, 203MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:   8% 83.9M/990M [00:00<00:03, 232MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  13% 126M/990M [00:00<00:03, 271MB/s] \u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  17% 168M/990M [00:00<00:02, 290MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  21% 210M/990M [00:00<00:02, 301MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  25% 252M/990M [00:00<00:02, 309MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  30% 294M/990M [00:01<00:02, 318MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  34% 336M/990M [00:01<00:02, 316MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00014.bin:  41% 409M/990M [00:01<00:01, 295MB/s]\n",
            "Downloading shards:  71% 10/14 [00:31<00:12,  3.17s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/autotrain\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('autotrain-advanced', 'console_scripts', 'autotrain')())\n",
            "  File \"/content/KoChatGPT/autotrain-advanced_231012/src/autotrain/cli/autotrain.py\", line 46, in main\n",
            "    command.run()\n",
            "  File \"/content/KoChatGPT/autotrain-advanced_231012/src/autotrain/cli/run_llm.py\", line 495, in run\n",
            "    train_llm(params)\n",
            "  File \"/content/KoChatGPT/autotrain-advanced_231012/src/autotrain/utils.py\", line 280, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/KoChatGPT/autotrain-advanced_231012/src/autotrain/trainers/clm/__main__.py\", line 124, in train\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3128, in from_pretrained\n",
            "    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n",
            "    cached_filename = cached_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 430, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1461, in hf_hub_download\n",
            "    http_get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 544, in http_get\n",
            "    temp_file.write(chunk)\n",
            "  File \"/usr/lib/python3.10/tempfile.py\", line 622, in func_wrapper\n",
            "    return func(*args, **kwargs)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm --train --project_name test                     --model TinyPixel/Llama-2-7B-bf16-sharded                     --data_path timdettmers/openassistant-guanaco                     --text_column \"text\" \\--use_peft                     --use_int4                     --learning_rate 2e-4                     --train_batch_size 2                     --num_train_epochs 2                     --trainer sft                     --model_max_length 2048                     --push_to_hub                     --repo_id keepsteady/test                     --block_size 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w9zh7Nlu3LUj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m-_5jFtq3LUj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "JvMRbVLEJlZT"
      },
      "outputs": [],
      "source": [
        "#@title 🤗 AutoTrain LLM\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload train.csv to a folder named `data/`\n",
        "#@markdown - train.csv must contain a `text` column\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can use most of the text-generation models from Hugging Face Hub\n",
        "#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7yIeAgVz5tP"
      },
      "source": [
        "project_name: checkpoint등 파일들의 저장 경로\n",
        "model: model 경로 (LLAMA2 2.7B 사용)\n",
        "data_path: 데이터 경로(ko-alpaca 데이터셋 사용)\n",
        "text_column: 데이터 중 사용할 칼럼 지정 ('text' 칼럼 사용)\n",
        "use_peft: parameter efficient fine tuning\n",
        "use_int4: integer 형태로\n",
        "learning_rate: 학습률 지정\n",
        "train_batch_size: 학습 배치사이즈\n",
        " A100의 경우 16, T4의 경우 2 추천\n",
        "num_train_epoch\n",
        "trainer: sft(supervised fine tuning)으로 지정\n",
        "model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tKyrYR2Bz4Ll"
      },
      "outputs": [],
      "source": [
        "#@title 🤗 AutoTrain LLM 입력 파라미터 설명\n",
        "#@markdown 학습하기 위해 아래 파라미터 입력 필요\n",
        "#@markdown - project_name: checkpoint등 파일들이 저장될 경로\n",
        "#@markdown - model: model 경로 (LLAMA2 2.7B 사용)\n",
        "#@markdown - data_path: 데이터 경로(ko-alpaca 데이터셋 사용)\n",
        "#@markdown - text_column: 데이터 중 사용할 칼럼 지정 ('text' 칼럼 사용)\n",
        "#@markdown - use_peft: parameter efficient fine tuning\n",
        "#@markdown - merge_adapter: PEFT로 학습된 부분을 실제 모델과 병합할 것인가?? 큰 모델로 만들지, 작은 부분만 저장할지 선택, True이면 전체 모델이 저장\n",
        "#@markdown - use_int4: integer 형태로\n",
        "#@markdown - learning_rate: 학습률 지정\n",
        "#@markdown - train_batch_size: 학습 배치사이즈, A100의 경우 16, T4의 경우 2 추천\n",
        "#@markdown - num_train_epoch: 몇번 반복학습 할지\n",
        "#@markdown - trainer: sft(supervised fine tuning)으로 지정\n",
        "#@markdown - model_max_length: 최대 생성 길이"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grNf-TUR5eQc"
      },
      "source": [
        "## Finetune config\n",
        "\n",
        "- 초기 모델: https://huggingface.co/TinyPixel/Llama-2-7B-bf16-sharded\n",
        "- 데이터셋(한국어): https://huggingface.co/datasets/royboy0416/ko-alpaca\n",
        "- 데이터셋(영어): https://huggingface.co/datasets/timdettmers/openassistant-guanaco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BI-UMjFT5des",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "b7ba8cdf3b1647cf85e2300b442cb053",
            "524de89a8d004f0186bf0fce7081cb2b",
            "90f40d9f6e0f4d409ceb014d029f805d",
            "3a4fad13b2d243dd99deaccba24538c0",
            "6791caccb1794dd893cca1f1aadd8782",
            "289b94d147dc4466b5e009ab8984a7a4",
            "169af424dd284593b6614c49e4a979f1",
            "b260330ab57146eeb3207bf912d894ff",
            "3963915877cd48c1b18e5ce673e2a399",
            "72e2de95da944aa8bd89fb9d4c42334e",
            "8c7efb4474144f038fe8aa0b0e55e519",
            "51a91f60c17e476f9072f9e0c0c2835c",
            "d913d071088e4f3b82e2ed4232cecf0b",
            "a27867a4fa7544e380598dd0ceeaa13b",
            "e413b76514104d07bdeaab6d47b6b955",
            "233fa010b74845a086b27d0337e0eb65",
            "ccce4048947c43eea9708fedf012ab33",
            "af908d37bb3b4c2fa62c0f9a9002d48e",
            "3dfa526bad714017abeb460da6c89701",
            "b188d170cc794726a84b00a6c8fba630",
            "2c28ec66f98040c7a1553e0d21886d24",
            "ee98041b51f24d2eb52cd02049dd4a29",
            "76666ddb18db42cf815e528f3c91a6e9",
            "9590fe21a580478893b5f525e4892bfa",
            "209d8bb9ce824c099fb4f355c0dec381",
            "d7f6b22604f9496aaacc61bd40a8651d",
            "3f91724454464ccc9415724f2ff9bf3e",
            "0ff7f6fc3c6a485e899b7bfbb5e36359",
            "6a356b8b5c4d4f30a12e670c5ed4f6dd",
            "c5962b3040dd46c5bfe7ba2ece9a057f",
            "f62ed9ccfe0e431cbb96a722fd109354",
            "b6c582e5fd2b46568eaf2eda73adb071",
            "cb57933a627b4509bbb78f577b3b6dba",
            "3eed97eb886940b2bbaf5f7d0346be16",
            "ef918b25acca46f8ac016f9123a121a2",
            "b6a9e6e01537418bbf2df82ac0058353",
            "7ae83d746e8240698d20880320937bd2",
            "f438b951adbc4be09039f742411b9718",
            "ced31689a87d4c9bb9429f41cbd59bb2",
            "311c8ab79dc5442d8dcc6ecf30d38ae3",
            "8ce2c327cb9f41dda94964b920a66f90",
            "63435100bfcf4d409c4be086ea59264c",
            "87b410d2dbfe496cb37bc065d7dec4d9",
            "67d6cc9d84b445d1a6b4a90c1e7c3ebd"
          ]
        },
        "outputId": "6424a128-8968-4d17-9817-ff82df06243f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7ba8cdf3b1647cf85e2300b442cb053"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/106k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51a91f60c17e476f9072f9e0c0c2835c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76666ddb18db42cf815e528f3c91a6e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eed97eb886940b2bbaf5f7d0346be16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output', 'text'],\n",
              "        num_rows: 120\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 작은 모델로 체크\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"aboonaji/alpaca_micro_demo\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A2-_lkBS1WKA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n",
        "project_name = 'my_autotrain_llm' # @param {type:\"string\"}\n",
        "model_name = 'abhishek/llama-2-7b-hf-small-shards' # @param {type:\"string\"}\n",
        "# data_path = 'royboy0416/ko-alpaca' # @param {type:\"string\"}\n",
        "data_path = 'aboonaji/alpaca_micro_demo' # @param {type:\"string\"}\n",
        "text_column = 'text' # @param {type:\"string\"}\n",
        "# royboy0416/ko-alpaca, timdettmers/openassistant-guanaco\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "repo_id = \"keepsteady/autotrain_test\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "#@markdown ###### A100: 16, T4: 2\n",
        "num_train_epochs = 1 #@param {type:\"number\"}\n",
        "learning_rate = 2e-4 # @param {type:\"number\"}\n",
        "train_batch_size = 2 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "block_size = 1024 # @param {type:\"number\"}\n",
        "trainer = \"sft\" # @param [\"default\", \"sft\"] {type:\"raw\"}\n",
        "warmup_ratio = 0.1 # @param {type:\"number\"}\n",
        "weight_decay = 0.01 # @param {type:\"number\"}\n",
        "gradient_accumulation_step = 4 # @param {type:\"number\"}\n",
        "use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_merge_adapter = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_int4 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "lora_r = 16 #@param {type:\"number\"}\n",
        "lora_alpha = 32 #@param {type:\"number\"}\n",
        "lora_dropout = 0.05 #@param {type:\"number\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_EPOCHS\"] = str(num_train_epochs)\n",
        "os.environ[\"BATCH_SIZE\"] = str(train_batch_size)\n",
        "os.environ[\"BLOCK_SIZE\"] = str(block_size)\n",
        "os.environ[\"WARMUP_RATIO\"] = str(warmup_ratio)\n",
        "os.environ[\"WEIGHT_DECAY\"] = str(weight_decay)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation_step)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"USE_PEFT\"] = str(use_peft)\n",
        "os.environ[\"USE_INT4\"] = str(use_int4)\n",
        "os.environ[\"LORA_R\"] = str(lora_r)\n",
        "os.environ[\"LORA_ALPHA\"] = str(lora_alpha)\n",
        "os.environ[\"LORA_DROPOUT\"] = str(lora_dropout)\n",
        "\n",
        "\n",
        "\n",
        "txt_fp16 = ' --fp16' if use_fp16 else ''\n",
        "txt_use_peft = ' --use_peft' if use_peft else ''\n",
        "txt_use_int4 = ' --use_int4' if use_int4 else ''\n",
        "txt_use_merge_adapter = ' --merge_adapter' if use_merge_adapter else ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMNkaLoiw88H",
        "outputId": "95150b7e-d5cd-48e7-8f98-d0d9dae961be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!autotrain llm --train --model \"abhishek/llama-2-7b-hf-small-shards\" --project_name \"my_autotrain_llm\" --data_path \"aboonaji/alpaca_micro_demo\" --text_column \"text\" --learning_rate 0.0002 --train_batch_size 2 --num_train_epochs 1 --block_size 1024 --warmup_ratio 0.1 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --weight_decay 0.01 --gradient_accumulation_steps 4 --trainer sft  --fp16 --use_peft --use_int4 --merge_adapter --push-to-hub --token \"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\" --repo-id \"keepsteady/autotrain_test\"\n"
          ]
        }
      ],
      "source": [
        "# Train!\n",
        "cmd = f'!autotrain llm \\\n",
        "--train \\\n",
        "--model \"{model_name}\" \\\n",
        "--project_name \"{project_name}\" \\\n",
        "--data_path \"{data_path}\" \\\n",
        "--text_column \"{text_column}\" \\\n",
        "--learning_rate {learning_rate} \\\n",
        "--train_batch_size {train_batch_size} \\\n",
        "--num_train_epochs {num_train_epochs} \\\n",
        "--block_size {block_size} \\\n",
        "--warmup_ratio {warmup_ratio} \\\n",
        "--lora_r {lora_r} \\\n",
        "--lora_alpha {lora_alpha} \\\n",
        "--lora_dropout {lora_dropout} \\\n",
        "--weight_decay {weight_decay} \\\n",
        "--gradient_accumulation_steps {gradient_accumulation_step} \\\n",
        "--trainer {trainer} \\\n",
        "{txt_fp16}{txt_use_peft}{txt_use_int4}{txt_use_merge_adapter} \\\n",
        "--push-to-hub --token \"{hf_token}\" --repo-id \"{repo_id}\"'\n",
        "\n",
        "print(cmd)\n",
        "!$command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3XZKnC03LUk"
      },
      "outputs": [],
      "source": [
        "!autotrain llm --train --model \"abhishek/llama-2-7b-hf-small-shards\" --project_name \"my_autotrain_llm\" --data_path \"aboonaji/alpaca_micro_demo\" --text_column \"text\" --learning_rate 0.0002 --train_batch_size 2 --num_train_epochs 1 --block_size 1024 --warmup_ratio 0.1 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --weight_decay 0.01 --gradient_accumulation_steps 4 --trainer sft  --fp16 --use_peft --use_int4 --merge_adapter --push-to-hub --token \"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\" --repo-id \"keepsteady/autotrain_test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IFZ2C_wH3LUk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmyHQcBA3LUk"
      },
      "source": [
        "# 학습한 Fine-tunning 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9NMGE3zQ3LUk"
      },
      "outputs": [],
      "source": [
        "# # 설치\n",
        "# !pip install -q transformers peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NCl5NJIk3LUk"
      },
      "outputs": [],
      "source": [
        "repo_id = 'keepsteady/autotrain_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M36hOrF53LUk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "TYg0jn5S3LUl",
        "outputId": "7c29d5eb-c7be-4063-b1b5-b0aa51a64875"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/config.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 config_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    106\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhf_hub_download_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './my_autotrain_llm/checkpoint-5'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-426928062077>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_model_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/config.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 )\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can't find '{CONFIG_NAME}' at '{pretrained_model_name_or_path}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mloaded_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't find 'adapter_config.json' at './my_autotrain_llm/checkpoint-5'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "model_id = \"TinyPixel/Llama-2-7B-bf16-sharded\"\n",
        "# # 구글드라이브에서 가져오기\n",
        "# peft_model_id = \"/content/drive/MyDrive/my_autotrain_llm/checkpoint-1222\"  # checkpoint 변경\n",
        "# # huggingface에서 가져오기\n",
        "# peft_model_id = 'keepsteady/autotrain_test'  # 학습 저장된 폴더경로\n",
        "# local에 저장된 폴더에서 모델 가져오기\n",
        "peft_model_id = './my_autotrain_llm/checkpoint-5'\n",
        "\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "\n",
        "# Huggingface에 저장된 README.md 에서 Training porcedure 값을 가져옴\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=False,\n",
        "    load_in_4bit=True,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_skip_modules=None,\n",
        "    llm_int8_enable_fp32_cpu_offload=False,\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_compute_dtype=\"float16\",\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model.eval()\n",
        "print('load model complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYIvNutt3LUl"
      },
      "outputs": [],
      "source": [
        "# data\n",
        "description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "\n",
        "\n",
        "지시 = 'Identify the odd one out.'\n",
        "입력 = 'Twitter, Instagram, Telegram'\n",
        "출력 = 'Telegram'\n",
        "\n",
        "text = f'{description}\\n### Instruction: {지시}\\n### Input: {입력}\\n### Response: {출력}'\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvBe3Xxp3LUl"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-OW4JMC3LUl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gen(Instruction=None, Input=None):\n",
        "\n",
        "    # 포맷 변경\n",
        "    description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "    if Input:\n",
        "        prompt = f'{description}\\n### Instruction: {Instruction}\\n### Input: {Input}\\n### Response: '\n",
        "    else:\n",
        "        prompt = f'{description}\\n### Instruction: {Instruction}\\n### Response: '\n",
        "\n",
        "    generated_txt = model.generate(\n",
        "        **tokenizer(\n",
        "            prompt,  # 프롬프트 입력\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=False\n",
        "        ).to('cuda'),\n",
        "        max_new_tokens=128,\n",
        "        early_stopping=True,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    answer = tokenizer.decode(generated_txt[0]).replace(prompt, \"\").lstrip('<s> ').rstrip('</s>').strip().split(\"\\n### \")[0].strip()\n",
        "    print(answer)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "output = gen(Instruction=\"생성형 AI로 업무를 자동화 할 수 있을까요?\", Input=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDphEk2t3LUl"
      },
      "outputs": [],
      "source": [
        "output = gen(Instruction=\"AI를 실제 업무에 적용하려면 어떤 프로세스가 필요해요?\", Input=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTNWdzAE3LUl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDNsGd8C3LUx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIJz2Xpy3LUx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "DmyHQcBA3LUk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7ba8cdf3b1647cf85e2300b442cb053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_524de89a8d004f0186bf0fce7081cb2b",
              "IPY_MODEL_90f40d9f6e0f4d409ceb014d029f805d",
              "IPY_MODEL_3a4fad13b2d243dd99deaccba24538c0"
            ],
            "layout": "IPY_MODEL_6791caccb1794dd893cca1f1aadd8782"
          }
        },
        "524de89a8d004f0186bf0fce7081cb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289b94d147dc4466b5e009ab8984a7a4",
            "placeholder": "​",
            "style": "IPY_MODEL_169af424dd284593b6614c49e4a979f1",
            "value": "Downloading data files: 100%"
          }
        },
        "90f40d9f6e0f4d409ceb014d029f805d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b260330ab57146eeb3207bf912d894ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3963915877cd48c1b18e5ce673e2a399",
            "value": 1
          }
        },
        "3a4fad13b2d243dd99deaccba24538c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72e2de95da944aa8bd89fb9d4c42334e",
            "placeholder": "​",
            "style": "IPY_MODEL_8c7efb4474144f038fe8aa0b0e55e519",
            "value": " 1/1 [00:00&lt;00:00,  4.11it/s]"
          }
        },
        "6791caccb1794dd893cca1f1aadd8782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289b94d147dc4466b5e009ab8984a7a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "169af424dd284593b6614c49e4a979f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b260330ab57146eeb3207bf912d894ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3963915877cd48c1b18e5ce673e2a399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72e2de95da944aa8bd89fb9d4c42334e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7efb4474144f038fe8aa0b0e55e519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a91f60c17e476f9072f9e0c0c2835c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d913d071088e4f3b82e2ed4232cecf0b",
              "IPY_MODEL_a27867a4fa7544e380598dd0ceeaa13b",
              "IPY_MODEL_e413b76514104d07bdeaab6d47b6b955"
            ],
            "layout": "IPY_MODEL_233fa010b74845a086b27d0337e0eb65"
          }
        },
        "d913d071088e4f3b82e2ed4232cecf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccce4048947c43eea9708fedf012ab33",
            "placeholder": "​",
            "style": "IPY_MODEL_af908d37bb3b4c2fa62c0f9a9002d48e",
            "value": "Downloading data: 100%"
          }
        },
        "a27867a4fa7544e380598dd0ceeaa13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dfa526bad714017abeb460da6c89701",
            "max": 105936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b188d170cc794726a84b00a6c8fba630",
            "value": 105936
          }
        },
        "e413b76514104d07bdeaab6d47b6b955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c28ec66f98040c7a1553e0d21886d24",
            "placeholder": "​",
            "style": "IPY_MODEL_ee98041b51f24d2eb52cd02049dd4a29",
            "value": " 106k/106k [00:00&lt;00:00, 469kB/s]"
          }
        },
        "233fa010b74845a086b27d0337e0eb65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccce4048947c43eea9708fedf012ab33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af908d37bb3b4c2fa62c0f9a9002d48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dfa526bad714017abeb460da6c89701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b188d170cc794726a84b00a6c8fba630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c28ec66f98040c7a1553e0d21886d24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee98041b51f24d2eb52cd02049dd4a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76666ddb18db42cf815e528f3c91a6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9590fe21a580478893b5f525e4892bfa",
              "IPY_MODEL_209d8bb9ce824c099fb4f355c0dec381",
              "IPY_MODEL_d7f6b22604f9496aaacc61bd40a8651d"
            ],
            "layout": "IPY_MODEL_3f91724454464ccc9415724f2ff9bf3e"
          }
        },
        "9590fe21a580478893b5f525e4892bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff7f6fc3c6a485e899b7bfbb5e36359",
            "placeholder": "​",
            "style": "IPY_MODEL_6a356b8b5c4d4f30a12e670c5ed4f6dd",
            "value": "Extracting data files: 100%"
          }
        },
        "209d8bb9ce824c099fb4f355c0dec381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5962b3040dd46c5bfe7ba2ece9a057f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f62ed9ccfe0e431cbb96a722fd109354",
            "value": 1
          }
        },
        "d7f6b22604f9496aaacc61bd40a8651d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c582e5fd2b46568eaf2eda73adb071",
            "placeholder": "​",
            "style": "IPY_MODEL_cb57933a627b4509bbb78f577b3b6dba",
            "value": " 1/1 [00:00&lt;00:00, 51.60it/s]"
          }
        },
        "3f91724454464ccc9415724f2ff9bf3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ff7f6fc3c6a485e899b7bfbb5e36359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a356b8b5c4d4f30a12e670c5ed4f6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5962b3040dd46c5bfe7ba2ece9a057f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f62ed9ccfe0e431cbb96a722fd109354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6c582e5fd2b46568eaf2eda73adb071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb57933a627b4509bbb78f577b3b6dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eed97eb886940b2bbaf5f7d0346be16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef918b25acca46f8ac016f9123a121a2",
              "IPY_MODEL_b6a9e6e01537418bbf2df82ac0058353",
              "IPY_MODEL_7ae83d746e8240698d20880320937bd2"
            ],
            "layout": "IPY_MODEL_f438b951adbc4be09039f742411b9718"
          }
        },
        "ef918b25acca46f8ac016f9123a121a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced31689a87d4c9bb9429f41cbd59bb2",
            "placeholder": "​",
            "style": "IPY_MODEL_311c8ab79dc5442d8dcc6ecf30d38ae3",
            "value": "Generating train split: "
          }
        },
        "b6a9e6e01537418bbf2df82ac0058353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ce2c327cb9f41dda94964b920a66f90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63435100bfcf4d409c4be086ea59264c",
            "value": 1
          }
        },
        "7ae83d746e8240698d20880320937bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87b410d2dbfe496cb37bc065d7dec4d9",
            "placeholder": "​",
            "style": "IPY_MODEL_67d6cc9d84b445d1a6b4a90c1e7c3ebd",
            "value": " 120/0 [00:00&lt;00:00, 5542.77 examples/s]"
          }
        },
        "f438b951adbc4be09039f742411b9718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced31689a87d4c9bb9429f41cbd59bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311c8ab79dc5442d8dcc6ecf30d38ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ce2c327cb9f41dda94964b920a66f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "63435100bfcf4d409c4be086ea59264c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87b410d2dbfe496cb37bc065d7dec4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d6cc9d84b445d1a6b4a90c1e7c3ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}